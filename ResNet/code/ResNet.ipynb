{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'train', 'val', 'wnids.txt', 'words.txt']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "from random import shuffle\n",
    "from IPython.display import Image, display\n",
    "from tqdm import tqdm\n",
    "from tensorflow.python import keras\n",
    "DIR = 'C:/Users/Leo/Desktop/Cambridge/Probably_right_notes/Computer_Vision/mini-project/tiny-imagenet-200/tiny-imagenet-200'\n",
    "file = os.listdir(DIR)\n",
    "print(file)\n",
    "\n",
    "img_rows, img_cols = 64,64\n",
    "num_classes = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "from keras import layers\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "import keras.backend as K\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "#from keras.applications.imagenet_utils import obtain_input_shape\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.layers import merge\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D,ZeroPadding2D,AveragePooling2D\n",
    "from keras.layers.core import Dense, Activation,Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Convolution2D, MaxPooling2D\n",
    "from keras.callbacks import Callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block1(x, nb_filter, kernel_size=3):\n",
    "    k1,k2,k3 = nb_filter\n",
    "    out = Convolution2D(k1,1,1)(x)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = LeakyReLU(alpha=0.01)(out)\n",
    "    #out = Activation('relu')(out)\n",
    "    \n",
    "    out = Convolution2D(k2,kernel_size,kernel_size,border_mode='same')(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = LeakyReLU(alpha=0.01)(out)\n",
    "    #out = Activation('relu')(out)\n",
    "    \n",
    "    out = Convolution2D(k3,1,1)(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    \n",
    "    out = layers.add([out,x])\n",
    "    out = LeakyReLU(alpha=0.01)(out)\n",
    "    \n",
    "    return out\n",
    "\n",
    "def block2(x, nb_filter, kernel_size=3):\n",
    "    k1,k2,k3 = nb_filter\n",
    "    out = Convolution2D(k1,1,1)(x)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = LeakyReLU(alpha=0.01)(out)\n",
    "    #out = Activation('relu')(out)\n",
    "    \n",
    "    out = Convolution2D(k2,kernel_size,kernel_size,border_mode='same')(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = LeakyReLU(alpha=0.01)(out)\n",
    "    #out = Activation('relu')(out)\n",
    "    \n",
    "    out = Convolution2D(k3,1,1)(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    \n",
    "        \n",
    "    x = Convolution2D(k3,1,1)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    out = layers.add([out,x])\n",
    "    out = LeakyReLU(alpha=0.01)(out)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.load('train_x12.npy')\n",
    "train_y = np.load('train_y12.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "train_xx = np.load('train_x3.npy')\n",
    "train_yx = np.load('train_y3.npy')\n",
    "print(train_xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\leo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (7, 7), strides=(2, 2))`\n",
      "  \"\"\"\n",
      "c:\\users\\leo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1))`\n",
      "c:\\users\\leo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), padding=\"same\")`\n",
      "c:\\users\\leo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1))`\n",
      "c:\\users\\leo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1))`\n",
      "c:\\users\\leo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1))`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\leo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), padding=\"same\")`\n",
      "  \n",
      "c:\\users\\leo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1))`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 142646 samples, validate on 7508 samples\n",
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "def ResNet8():\n",
    "    \n",
    "    inp = Input(shape=(img_rows,img_cols,3))\n",
    "    out = ZeroPadding2D((3,3))(inp)\n",
    "    out = Convolution2D(64,7,7,subsample=(2,2))(inp)\n",
    "    out = BatchNormalization()(out) # same function as dropout\n",
    "    out = LeakyReLU(alpha=0.01)(out)\n",
    "    out = MaxPooling2D((3,3),strides=(2,2))(out)\n",
    "    \n",
    "   \n",
    "    out = block2(out,[256,256,1024])\n",
    "    out = block1(out,[256,256,1024])\n",
    "    out = block1(out,[256,256,1024])\n",
    "    out = block1(out,[256,256,1024])\n",
    "\n",
    "    \n",
    "    \n",
    "    out = AveragePooling2D((7,7))(out)\n",
    "    out = Flatten()(out)\n",
    "    out = Dense(200, activation='softmax')(out)\n",
    "    \n",
    "    \n",
    "    model = Model(inp,out)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = ResNet8()\n",
    "model.compile(loss='poisson',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(train_x,train_y,batch_size=100,epochs=2,verbose=2,validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 142646 samples, validate on 7508 samples\n",
      "Epoch 1/10\n",
      " - 942s - loss: 0.0190 - acc: 0.3531 - val_loss: 0.0200 - val_acc: 0.3181\n",
      "Epoch 2/10\n",
      " - 929s - loss: 0.0170 - acc: 0.4281 - val_loss: 0.0199 - val_acc: 0.3247\n",
      "Epoch 3/10\n",
      " - 904s - loss: 0.0154 - acc: 0.4935 - val_loss: 0.0193 - val_acc: 0.3522\n",
      "Epoch 4/10\n",
      " - 904s - loss: 0.0140 - acc: 0.5516 - val_loss: 0.0171 - val_acc: 0.4254\n",
      "Epoch 5/10\n",
      " - 907s - loss: 0.0128 - acc: 0.6045 - val_loss: 0.0175 - val_acc: 0.4330\n",
      "Epoch 6/10\n",
      " - 910s - loss: 0.0116 - acc: 0.6564 - val_loss: 0.0174 - val_acc: 0.4362\n",
      "Epoch 7/10\n",
      " - 919s - loss: 0.0105 - acc: 0.7079 - val_loss: 0.0170 - val_acc: 0.4603\n",
      "Epoch 8/10\n",
      " - 935s - loss: 0.0094 - acc: 0.7572 - val_loss: 0.0172 - val_acc: 0.4635\n",
      "Epoch 9/10\n",
      " - 962s - loss: 0.0085 - acc: 0.8052 - val_loss: 0.0175 - val_acc: 0.4694\n",
      "Epoch 10/10\n",
      " - 968s - loss: 0.0077 - acc: 0.8443 - val_loss: 0.0180 - val_acc: 0.4736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c77d19b278>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='poisson',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(train_x,train_y,batch_size=100,epochs=10,verbose=2,validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 142646 samples, validate on 7508 samples\n",
      "Epoch 1/5\n",
      " - 979s - loss: 0.0072 - acc: 0.8740 - val_loss: 0.0180 - val_acc: 0.4828\n",
      "Epoch 2/5\n",
      " - 982s - loss: 0.0066 - acc: 0.9043 - val_loss: 0.0183 - val_acc: 0.4826\n",
      "Epoch 3/5\n",
      " - 992s - loss: 0.0063 - acc: 0.9219 - val_loss: 0.0186 - val_acc: 0.4812\n",
      "Epoch 4/5\n",
      " - 974s - loss: 0.0061 - acc: 0.9349 - val_loss: 0.0196 - val_acc: 0.4702\n",
      "Epoch 5/5\n",
      " - 976s - loss: 0.0059 - acc: 0.9439 - val_loss: 0.0193 - val_acc: 0.4988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c77ca60fd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='poisson',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(train_x,train_y,batch_size=100,epochs=5,verbose=2,validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ResNet14.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "del model  # deletes the existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('ResNet14.h5') # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 142646 samples, validate on 7508 samples\n",
      "Epoch 1/3\n",
      " - 1012s - loss: 0.0059 - acc: 0.9461 - val_loss: 0.0202 - val_acc: 0.4879\n",
      "Epoch 2/3\n",
      " - 948s - loss: 0.0057 - acc: 0.9558 - val_loss: 0.0196 - val_acc: 0.5003\n",
      "Epoch 3/3\n",
      " - 1033s - loss: 0.0057 - acc: 0.9605 - val_loss: 0.0205 - val_acc: 0.4871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x292fcfcef98>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='poisson',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(train_x,train_y,batch_size=100,epochs=3,verbose=2,validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 64, 64, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\leo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (7, 7), strides=(2, 2))`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 14, 14, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\leo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1))`\n",
      "c:\\users\\leo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), padding=\"same\")`\n",
      "c:\\users\\leo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1))`\n",
      "c:\\users\\leo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 14, 14, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\leo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1))`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\leo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), padding=\"same\")`\n",
      "  \n",
      "c:\\users\\leo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (1, 1))`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-b31117df828b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mResNet8\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'poisson'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_x' is not defined"
     ]
    }
   ],
   "source": [
    "def ResNet8():\n",
    "    \n",
    "    inp = Input(shape=(img_rows,img_cols,3))\n",
    "    print(inp.shape)\n",
    "    out = ZeroPadding2D((3,3))(inp)\n",
    "    out = Convolution2D(64,7,7,subsample=(2,2))(inp)\n",
    "    out = BatchNormalization()(out) # same function as dropout\n",
    "    out = LeakyReLU(alpha=0.01)(out)\n",
    "    out = MaxPooling2D((3,3),strides=(2,2))(out)\n",
    "    print(out.shape)\n",
    "   \n",
    "    out = block2(out,[256,256,1024])\n",
    "    print(out.shape)\n",
    "    out = block1(out,[256,256,1024])\n",
    "    out = block1(out,[256,256,1024])\n",
    "    out = block1(out,[256,256,1024])\n",
    "    \n",
    "    \n",
    "    out = AveragePooling2D((7,7))(out)\n",
    "    out = Flatten()(out)\n",
    "    out = Dense(200, activation='softmax')(out)\n",
    "    \n",
    "    \n",
    "    model = Model(inp,out)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = ResNet8()\n",
    "model.compile(loss='poisson',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(train_x,train_y,batch_size=100,epochs=20,verbose=2,validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 95000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      " - 648s - loss: 0.0190 - acc: 0.3550 - val_loss: 0.0183 - val_acc: 0.3772\n",
      "Epoch 2/20\n",
      " - 553s - loss: 0.0142 - acc: 0.5370 - val_loss: 0.0173 - val_acc: 0.4374\n",
      "Epoch 3/20\n",
      " - 552s - loss: 0.0117 - acc: 0.6529 - val_loss: 0.0177 - val_acc: 0.4322\n",
      "Epoch 4/20\n",
      " - 552s - loss: 0.0096 - acc: 0.7538 - val_loss: 0.0177 - val_acc: 0.4462\n",
      "Epoch 5/20\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_xx,train_yx,batch_size=100,epochs=20,verbose=2,validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 95000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      " - 553s - loss: 0.0058 - acc: 0.9552 - val_loss: 0.0224 - val_acc: 0.4302\n",
      "Epoch 2/20\n",
      " - 554s - loss: 0.0056 - acc: 0.9668 - val_loss: 0.0219 - val_acc: 0.4408\n",
      "Epoch 3/20\n",
      " - 553s - loss: 0.0056 - acc: 0.9682 - val_loss: 0.0229 - val_acc: 0.4276\n",
      "Epoch 4/20\n",
      " - 553s - loss: 0.0055 - acc: 0.9711 - val_loss: 0.0232 - val_acc: 0.4272\n",
      "Epoch 5/20\n",
      " - 564s - loss: 0.0055 - acc: 0.9751 - val_loss: 0.0236 - val_acc: 0.4306\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-a41b28f984b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_xx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_yx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\leo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\leo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\leo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2664\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2666\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2667\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\leo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2635\u001b[0m                                 session)\n\u001b[1;32m-> 2636\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2637\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\leo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_xx,train_yx,batch_size=100,epochs=20,verbose=2,validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_acc(model,datax,datay):\n",
    "    preds = model.predict(datax)\n",
    "    pred_index = np.argmax(preds, axis=1)\n",
    "    trainlabel = np.argmax(datay,axis=1)\n",
    "    bolcom = np.equal(trainlabel,pred_index)\n",
    "    test_accuracy = sum(bolcom)/pred_index.shape*100\n",
    "    print('Test Accuracy',test_accuracy)\n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy [40.324]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([40.324])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc(model,train_x[:],train_y[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
